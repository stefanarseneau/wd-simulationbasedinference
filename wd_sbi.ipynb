{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corv\n",
    "import pyphot\n",
    "from pyphot import unit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pygaia.errors.astrometric import parallax_uncertainty\n",
    "import lightning as pl\n",
    "import scipy.stats as ss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = corv.models.Spectrum('1d_da_nlte')\n",
    "library = pyphot.get_library()\n",
    "\n",
    "def forward(teff, distance, radius, bands = ['Gaia_G', 'Gaia_BP', 'Gaia_RP', 'SDSS_u', 'SDSS_g', 'SDSS_r', 'SDSS_i', 'SDSS_z']):\n",
    "    pc_to_m = 3.0856775814671916e16\n",
    "    rsun_to_m = 6.957e8\n",
    "    bands = [library[band] for band in bands]\n",
    "    wavl, interp = model.wavl, model.model_spec\n",
    "    flux = interp((teff, 8)) * ((radius*rsun_to_m) / (distance * pc_to_m))**2\n",
    "    band_flux = np.array([band.get_flux(wavl * unit['AA'], flux * unit['erg/s/cm**2/AA'], axis=1).value for band in bands])\n",
    "    return band_flux\n",
    "\n",
    "def sim_forward(teff, distance, radius, bands = ['Gaia_G', 'Gaia_BP', 'Gaia_RP', 'SDSS_u', 'SDSS_g', 'SDSS_r', 'SDSS_i', 'SDSS_z']):\n",
    "    snr = np.random.uniform(300, 400)\n",
    "    band_flux = forward(teff, distance, radius, bands)\n",
    "    band_flux_noisy = np.random.normal(band_flux, band_flux/snr)\n",
    "\n",
    "    gmag = -2.5 * np.log10(band_flux_noisy[0] / 2.4943e-09)\n",
    "    plx_unc = parallax_uncertainty(gmag, release='dr3') * 1e-6\n",
    "    plx = np.random.normal(loc = -0.000014 + (1 / distance), scale = plx_unc, size=(1))\n",
    "    plx_data = np.concatenate([plx, np.array([plx_unc])])\n",
    "\n",
    "    obs = np.concatenate([band_flux_noisy, band_flux_noisy/snr])\n",
    "    return np.concatenate([plx_data, obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['Gaia_G', 'Gaia_BP', 'Gaia_RP', 'SDSS_u', 'SDSS_g', 'SDSS_r', 'SDSS_i', 'SDSS_z']\n",
    "wavl = np.array([library[band].lpivot.to('AA').value for band in bands])\n",
    "\n",
    "theta = np.array([10000, 100, 0.02])\n",
    "data = sim_forward(*theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.02357296e-02, 2.68655668e-04, 6.65447119e-17, 1.03527262e-16,\n",
       "       3.61357854e-17, 1.58747906e-16, 1.27152231e-16, 6.94802342e-17,\n",
       "       4.17122099e-17, 2.44718734e-17, 2.11617432e-19, 3.29224857e-19,\n",
       "       1.14914647e-19, 5.04830860e-19, 4.04354122e-19, 2.20952624e-19,\n",
       "       1.32648117e-19, 7.78224872e-20])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "n_train = 50_000\n",
    "\n",
    "# Simulate training data\n",
    "theta_samples = np.random.uniform(low=[2000, 5, 0.004], high=[80000, 400, 0.025], size=(n_train, 3))  # Parameter proposal\n",
    "x_samples = np.array([sim_forward(*theta, bands) for theta in tqdm(theta_samples)])\n",
    "\n",
    "np.save('data/wdparams_theta.npy', theta_samples)\n",
    "np.save('data/wdparams_x.npy', x_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = np.load('data/wdparams_theta.npy')\n",
    "x_samples = np.load('data/wdparams_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensors\n",
    "theta_samples = torch.tensor(theta_samples, dtype=torch.float32)\n",
    "x_samples = torch.tensor(x_samples, dtype=torch.float32)\n",
    "\n",
    "# Normalize the data\n",
    "x_mean = x_samples.mean(dim=0)\n",
    "x_std = x_samples.std(dim=0)\n",
    "x_samples = (x_samples - x_mean) / x_std\n",
    "\n",
    "theta_mean = theta_samples.mean(dim=0)\n",
    "theta_std = theta_samples.std(dim=0)\n",
    "theta_samples = (theta_samples - theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fraction = 0.1\n",
    "batch_size = 128\n",
    "n_samples_val = int(val_fraction * len(x_samples))\n",
    "\n",
    "dataset = TensorDataset(x_samples, theta_samples)\n",
    "\n",
    "dataset_train, dataset_val = random_split(dataset, [len(x_samples) - n_samples_val, n_samples_val])\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, num_workers=8, pin_memory=True, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, num_workers=8, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_dim, hidden_dim, output_dim, layers, activation=nn.GELU()):\n",
    "    \"\"\"Create an MLP from the configuration.\"\"\"\n",
    "    seq = [nn.Linear(input_dim, hidden_dim), activation]\n",
    "    for _ in range(layers):\n",
    "        seq += [nn.Linear(hidden_dim, hidden_dim), activation]\n",
    "    seq += [nn.Linear(hidden_dim, output_dim)]\n",
    "    return nn.Sequential(*seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.4011,  6.0815,  7.3929,  4.7498,  5.4776,  5.4342,  8.3729,  4.2657,\n",
       "         5.5075,  4.8850,  5.1368,  4.6958, 10.1272,  5.6320,  4.5572,  9.6612,\n",
       "         4.3191,  4.7034,  7.0259,  4.8684,  4.5701,  6.6495,  5.4175,  4.5372,\n",
       "         5.7163,  5.8074,  4.5168,  6.2378,  4.6474,  5.3631,  4.9059,  6.8138,\n",
       "         5.6715,  7.4841,  4.9223,  4.7750,  4.3819,  5.3928,  4.6456,  4.8493,\n",
       "         5.7530,  5.1606,  6.2276,  4.3525,  5.8932,  4.5460,  7.9270,  4.3353,\n",
       "         5.9612,  6.2757,  4.2584,  4.2580,  4.2507,  4.4894,  4.3637,  4.6333,\n",
       "         4.2999,  7.0702,  4.6815,  4.5610,  4.5417,  4.7290,  5.2863,  5.4418,\n",
       "         4.4018,  4.4634,  4.2602,  4.2982,  4.8673,  4.5128, 11.2834,  4.7663,\n",
       "         4.5700,  4.6823,  5.0551,  4.9327,  4.6028,  5.1573,  4.7507,  5.6117,\n",
       "         4.2989,  6.3357,  4.3556,  4.4369,  4.6389,  8.3202,  4.5011,  4.3312,\n",
       "         4.2555,  4.5455,  5.0900,  4.4288,  5.1532,  6.1299,  4.4132,  4.4420,\n",
       "         5.6807,  4.9302,  5.7718,  4.4670], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_flow(d_in=2, d_hidden=32, d_context=16, n_layers=4):\n",
    "    \"\"\" Instantiate a simple (Masked Autoregressive) normalizing flow.\n",
    "    \"\"\"\n",
    "    base_dist = StandardNormal(shape=[d_in])\n",
    "\n",
    "    transforms = []\n",
    "    for _ in range(n_layers):\n",
    "        transforms.append(ReversePermutation(features=d_in))\n",
    "        transforms.append(MaskedAffineAutoregressiveTransform(features=d_in, hidden_features=d_hidden, context_features=d_context))\n",
    "    transform = CompositeTransform(transforms)\n",
    "\n",
    "    flow = Flow(transform, base_dist)\n",
    "    return flow\n",
    "\n",
    "# Instantiate flow\n",
    "flow = get_flow()\n",
    "\n",
    "# Make sure sampling and log-prob calculation makes sense\n",
    "samples, log_prob = flow.sample_and_log_prob(num_samples=100, context=torch.randn(2, 16))\n",
    "-log_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGwCAYAAAA0bWYRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSE0lEQVR4nO3dd3hUZcLG4d/MZCaZtEkCCSShG3oXUINgEFEUWXXtrLJY1goqir2i7q7uuijqrsi6FnQ/F1QUERUFFQRBQCBSRXoJgUBI78mc74+BgUBAyiRnynNfV65MOTPzcEDz5Jz3vK/FMAwDERERCVlWswOIiIiIuVQGREREQpzKgIiISIhTGRAREQlxKgMiIiIhTmVAREQkxKkMiIiIhLiw49nI7Xazc+dOYmJisFgs9Z1JREREfMAwDIqKikhJScFqPfrv/8dVBnbu3Enz5s19Fk5EREQazvbt22nWrNlRnz+uMhATE+N9s9jYWN8kExERkXpVWFhI8+bNvT/Hj+a4ysCBUwOxsbEqAyIiIgHmt07xawChiIhIiFMZEBERCXEqAyIiIiHuuMYMiIhIcHK73VRWVpodQ06S3W7HZrOd8vuoDIiIhKjKyko2b96M2+02O4qcgri4OJo2bXpK8wCpDIiIhCDDMMjOzsZms9G8efNjTkgj/skwDEpLS8nJyQEgOTn5pN9LZUBEJARVV1dTWlpKSkoKkZGRZseRk+R0OgHIyckhKSnppE8ZqAqKiISgmpoaABwOh8lJ5FQdKHNVVVUn/R4qAyIiIUzrzQQ+X/wdqgyIiIiEOI0ZEBERr6z8MvJKGu5Sw/goB6lxzgb7PKmbyoCIiACeIjBo3FzKqmoa7DOddhuzx2QEfCG44YYbyM/PZ9q0aWZHOSkqAyIiAkBeSSVlVTWMv6YHaUnR9f55G3KKGT0lk7ySyoAvA4FOZUBERGpJS4qmS6rL7BjSgDSA0GRZ+WWsyirwfmXll5kdSUTEr3300Ud07doVp9NJo0aNGDRoECUlJSxZsoTzzz+fxo0b43K5yMjIYNmyZbVea7FYmDhxIkOHDiUyMpKOHTuycOFCNmzYwIABA4iKiiI9PZ2NGzd6XzN27Fh69OjBxIkTad68OZGRkVx11VXk5+cfNaNhGPz973+nTZs2OJ1OunfvzkcffeR9Pi8vj+uuu47ExEScTidt27bl7bff9vm+Ol4qAyY6cH5u6KvzvV+Dxs1VIRAROYrs7GyGDRvGTTfdxNq1a5kzZw6XX345hmFQVFTEiBEjmDdvHj/++CNt27ZlyJAhFBUV1XqPZ599lj/+8Y9kZmbSoUMH/vCHP3DbbbfxyCOP8NNPPwEwatSoWq/ZsGEDH3zwAZ999hkzZ84kMzOTkSNHHjXn448/zttvv82ECRNYvXo19957L9dffz1z584F4IknnmDNmjV8+eWXrF27lgkTJtC4cWMf763jp9MEJjr8/JzOn4mIHFt2djbV1dVcfvnltGzZEoCuXbsCMHDgwFrbTpw4kfj4eObOncvQoUO9j994441cffXVADz00EOkp6fzxBNPMHjwYADuuecebrzxxlrvVV5ezqRJk2jWrBkAr776KhdffDHjxo2jadOmtbYtKSnhxRdf5NtvvyU9PR2ANm3aMH/+fCZOnEhGRgbbtm2jZ8+e9O7dG4BWrVr5YvecNB0Z8AMHzs81xIAdEZFA1r17d8477zy6du3KVVddxRtvvEFeXh7gmZL39ttvp127drhcLlwuF8XFxWzbtq3We3Tr1s17u0mTJsDBQnHgsfLycgoLC72PtWjRwlsEANLT03G73axbt+6IjGvWrKG8vJzzzz+f6Oho79e7777rPf1wxx13MHnyZHr06MGDDz7IggULfLB3Tp6ODIiISMCw2WzMmjWLBQsW8PXXX/Pqq6/y2GOPsWjRIkaOHMmePXsYP348LVu2JDw8nPT09COWaLbb7d7bB2bvq+uxY63meGCbumb/O/C6zz//nNTU1FrPhYeHA3DRRRexdetWPv/8c2bPns15553HyJEj+cc//nHc+8KXVAbq0eGTd2hyDRGRU2exWDj77LM5++yzefLJJ2nZsiWffPIJ8+bN47XXXmPIkCEAbN++nb179/rkM7dt28bOnTtJSUkBYOHChVitVtq1a3fEtp06dSI8PJxt27aRkZFx1PdMTEzkhhtu4IYbbqB///488MADKgPBpq7JO4Jlcg0RCW4bcor99nMWLVrEN998wwUXXEBSUhKLFi1iz549dOzYkbS0NN577z169+5NYWEhDzzwgHdVv1MVERHBiBEj+Mc//kFhYSF33303V1999RHjBQBiYmK4//77uffee3G73fTr14/CwkIWLFhAdHQ0I0aM4Mknn6RXr1507tyZiooKZsyYQceOHX2S9WSoDNQTDQ4UkUATH+XAabcxekpmg32m024jPur4V06MjY3l+++/Z/z48RQWFtKyZUvGjRvHRRddRNOmTbn11lvp2bMnLVq04K9//Sv333+/T3KmpaVx+eWXM2TIEPbt28eQIUN47bXXjrr9s88+S1JSEs899xybNm0iLi6O008/nUcffRTwrBb5yCOPsGXLFpxOJ/3792fy5Mk+yXoyVAbqmSbvEJFAkRrnZPaYDL9em6Bjx47MnDmzzud69uzJkiVLaj125ZVX1rpvGEat+61atTrisQEDBhzxGHgG/d1xxx11fvY777xT677FYuHuu+/m7rvvrnP7xx9/nMcff7zO58ygMiAiIl6pcU4dvQxBurRQREQkxKkMiIiIHMPYsWPJzMw0O0a9UhkQEREJcSoDIiIiIU5lQEREJMSpDIiIiIQ4lQEREZEQpzIgIiLiJ+bMmYPFYiE/P9/72LRp00hLS8NmszF69Oh6+VyVARERkRNgsViYNm1ag33ebbfdxpVXXsn27dt59tln6+UzNAOhiIiInyouLiYnJ4fBgwd7V0ysDzoyYLKLrIuIzF4ENdVmRxER8XuGYfD3v/+dNm3a4HQ66d69Ox999JH3uUGDBnHhhRd61xbIz8+nRYsWPPbYYwDU1NRw880307p1a5xOJ+3bt+fll18+4nPeeustOnfuTHh4OMnJyYwaNQrwrGUA8Pvf/x6LxeK9f7gtW7ZgsViYPHkyffv2JSIigs6dOzNnzpxa233xxRe0a9cOp9PJueeey5YtW7zPzZkzh5iYGAAGDhyIxWI54vW+ojLQgDpbNhP360e1Hnsk7H3azLgKXupMwup3sFFzlFeLiDSAypKjf1WVn8C2Zce37Ql6/PHHefvtt5kwYQKrV6/m3nvv5frrr2fu3LlYLBYmTZrE4sWLeeWVVwC4/fbbadKkCWPHjgXA7XbTrFkzPvjgA9asWcOTTz7Jo48+ygcffOD9jAkTJjBy5EhuvfVWVq5cyfTp00lLSwPwLoT09ttvk52dfcTCSId74IEHGDNmDMuXL6dv375ccskl5ObmArB9+3bvSoiZmZn86U9/4uGHH/a+tm/fvqxbtw6AqVOnkp2dTd++fU94nx0PnSZoII1WvMGnjr9g+SEC+vwOopMAyDTSSAmvJqx4FykLnuRzR3Ns+96C1DNMTiwiIemvxzgU3fYCuO7Dg/dfSIOq0rq3bdkPbvz84P3xXaE098jtxhYcd7SSkhJefPFFvv32W9LT0wFo06YN8+fPZ+LEiWRkZJCamsrEiRMZPnw4u3fv5rPPPmP58uXY7XYA7HY7Tz/9tPc9W7duzYIFC/jggw+4+uqrAfjzn//MmDFjuOeee7zb9enTB4DExEQA4uLiaNq06W9mHjVqFFdccQXgKRkzZ87kzTff5MEHH2TChAm0adOGl156CYvFQvv27Vm5ciV/+9vfAM8yx0lJnp8VCQkJx/V5J0tloL4ZBnz7Z5IXvQAWKGgxkEMXNL676i5Ou+4MOu/+lOrZz9KhYjs10y+HiHeg7SCzUouI+J01a9ZQXl7O+eefX+vxyspKevbs6b1/1VVX8cknn/Dcc88xYcIE2rVrV2v7119/nf/85z9s3bqVsrIyKisr6dGjBwA5OTns3LmT8847zyeZD5QWgLCwMHr37s3atWsBWLt2LWeddRYWi6XO7RuSykA9S8z8F/z0AgDPV13L0PP+jivaVWsbw+aAPn9iffxACt8dxplVv8D7V8Pt86BJZzNii0ioenTn0Z+z2Grff2DDMbY97Cz06JUnn2k/t9sNwOeff05qamqt58LDw723S0tLWbp0KTabjfXr19fa7oMPPuDee+9l3LhxpKenExMTwwsvvMCiRYsAcDrrf/nmAz/8D4xr8AcqA/Wor3UVSfuLQHb6U7z+XXuGHmP7Gmcjhlc+wjdpH+Bo0oE9VamQVUB8lEPri4tIw3BEmb/tUXTq1Inw8HC2bdtGRkbGUbcbM2YMVquVL7/8kiFDhnDxxRczcOBAAObNm0ffvn258847vdtv3LjRezsmJoZWrVrxzTffcO6559b5/na7nZqa4xvf9eOPP3LOOecAUF1dzdKlS72DETt16nTEJYo//vjjcb2vr6kM1JOw0t28bP8nFgzoOZzcLjfDd/OP+Zr4KAc2ewT9N/wBNljghx8AcNptzB6ToUIgIiEtJiaG+++/n3vvvRe3202/fv0oLCxkwYIFREdHM2LECD7//HPeeustFi5cyOmnn87DDz/MiBEjWLFiBfHx8aSlpfHuu+/y1Vdf0bp1a9577z2WLFlC69atvZ8zduxYbr/9dpKSkrjooosoKirihx9+4K677gLwloWzzz6b8PBw4uPjj5r5X//6F23btqVjx4689NJL5OXlcdNNNwGewY3jxo3jvvvu47bbbmPp0qW888479boPj8o4DgUFBQZgFBQUHM/mYhjGmg2bjPcfu9QofSXdMCpLjZU78o2WD80wVu7I925T12M78jzbHviavnid8fJjfzRWbdllxh9DRIJUWVmZsWbNGqOsrMzsKCfE7XYbL7/8stG+fXvDbrcbiYmJxuDBg425c+caOTk5RpMmTYy//vWv3u2rqqqMM844w7j66qsNwzCM8vJy44YbbjBcLpcRFxdn3HHHHcbDDz9sdO/evdbnvP76697PSE5ONu666y7vc9OnTzfS0tKMsLAwo2XLlnXm3Lx5swEY77//vnHmmWcaDofD6Nixo/HNN9/U2u6zzz4z0tLSjPDwcKN///7GW2+9ZQBGXl6eYRiGkZeXZwDGd999d9R9cqy/y+P9+W0xjN8+aVFYWIjL5aKgoIDY2Nh6rifBYVVWAUNfnc/nd55B5xaJ3vsz7upHl1RXrW0OfawWw6Dk3xcSlf0juR2H0+iafwKQlV9GXkllrU11KkFETkR5eTmbN2+mdevWREREmB0n6GzZsoXWrVuzfPly7+DE+nKsv8vj/fmt0wT1zLA5Tv7FFgt7eowiKvtHGq19DzZdSVbCmQwaN5eyqtrnq3QqQURETpbKgK+t+BDWTiei4x0+ebviZucwqfp8RoTNgk/vouCymZRV1TD+mh6kJUUDsCGnmNFTMskrqVQZEBGRE6Yy4EtuN8z7B+z5hZioDkAPn7zt36qHMSzuFxwF20ha+g9gEGlJ0XWfWhAREdO1atXKry4d/C2ajtiXfpkBe36BcBe5nf/os7ctJYKs/s8B0Gj1JNpZtvvsvUVERFQGfMUwYN44z+0zb8Xt8O1Ay5Jm50CHoViMGh4Mm+zT9xaR0BVIv71K3Xzxd6gy4CN71s6H7EzctnDWtryODTnFvv+QwX8lr+2VPFr1J9+/t4iEFJvNM5tgZWXlb2wp/q601LM+xIH1F06Gxgz4QFZ+GYsnv8DvrTC14kweeGMN4BnhHx91ClcTHGJDTjEkxbGh0zPkrMz0yXuKSOgKCwsjMjKSPXv2YLfbsVr1u2GgMQyD0tJScnJyiIuL8xa8k6Ey4AMF+3K4yLIAgNMvv48ZTU4HfHPtf3yUA6fdxugpmd7HvCWjvBAiNO+DiJw4i8VCcnIymzdvZuvWrWbHkVNwvCsoHovKgC9Ywnih+mrubruP03oOgENWoDpVqXFOZo/JqDXJUCPySJ75J9i9GkYdey1tEZGjcTgctG3bVqcKApjdbj+lIwIHqAz4gNsRzZs1F/P78/vh8mEROCA1zln7CENlGGxfDCU5sPw9SL7C558pIqHBarVqBkLRAMKA5IiC/mM8t+f+HUt1ubl5REQkoOnIwEk6sD6Aa8MnVBSUEU3jhg3Q+0ZY8AoUZhG3firQsmE/X0REgoaODJyErPwyBo2by9BX51H1zXP0WvYwFzp+9tmVA8clLBzSRwLQeMVErLgb7rNFRCSoqAychLySSsqqanh7sIM21l24bRHcN2r0cV05sCGnmFVZBazKKjj1uQhOHwERcYQXbmGwVQMJRUTk5Og0wSnokjcbAGuHi0hJOvZpgrouEYRTnIsgPBrOuAW+f4Frbd+xIee2Wp+nRYtEROR4qAycgtitszw3Ol7ym9vWdYkg+OCH9pm3k2+LZ/TsZuQdNheBljQWEZHjoTJwklpbsgkv2ATWMEgbdFyvOeISQV+IakxcxkhmdC/zFg0taSwiIidCZeAkDbQu89xoebZfzAKYGuck1RUBVWVAtNlxREQkgKgMnKQWlhwMLFjaX2R2FI/1s+Hrx6H1OdD9MYAjBihqHIGIiNRFZeAkPVV9I2eMeJ6OzRqZHcXDYoE9a6FgBwm9HzjqYEWNIxARkcOpDJyCmshEcLrMjuHR5lxo1BZy15OyZRqzx1xfa7CixhGIiMjRaJ6Bk+GuMTvBkaxWOONWz+3F/ybVFUGXVJf3Ky1J4whERKRuKgMnyjBo++FA/mf/M/bCbWanqa3HMHDEwN5fYdN3ZqcREZEAoTJwovZtIrxwM6dbf6Xa2cDrEfyW8Bjo8QfP7Z/eMjeLiIgEDJWBE7X/N+5l7nYY9kiTw9Sh1wjP93VfQnGOuVlERCQgaADhido0B4D57i74yUWFtTXpDP3uhVb9INJPrnQQERG/pjJwItw1sPl7AH7w1zIAMGis2QlERCSA6DTBicj+GcoLqHHEstJobXYaERERn9CRgROxbSEAJU37UFNoMznMbyjYAYv/DTXVcOFfzU4jIiJ+TEcGTkR8K2h3EcXNzzU7yW8r2g0/vAw/vQlleWanERERP6YjA8chK3//ioAx/SCj3/45/zPNjnVsqadDUmfIWQ0rP4LUq81OJCIifkpl4Ddk5ZcxaNxcyqpqzzrotNuIj3KYlOo4WCyeywy/fBCWToKUq8xOJCIifkpl4DfklVRSVlXDv4cm0LJxLFUxzYAAWQGw61Xw9ROweyURuavMTiMiIn5KYwaOU5+tb9B+cl+6bPoPXVJd/l8EACIToMMQAOLWf2xyGBER8VcqA8cpatcSz43k7uYGOVHdhwEQt/FTwqg2OYyIiPgjnSaog3fAIJ6lfxPJx1G0DbBAszPMDXeiThsIiR0oSDyLyLwKs9OIiIgfUhk4TF0DBofYN3tuJHWEiFiTkp0kmx3u/JHsnYUULptvdhoREfFDKgOHOTBgcPw1PUhLigagZeYiWILncr1AZLGYnUBERPyYysBRpCVF0yXV5bkzO9PzPbW3aXlOmeHmDMtaIrPtkHqB2WlERMSPaADhb3G7Yedyz+1mgVsGElZP4oPwZ2ny0wtmRxERET+jMvBbjBr43XhIHwWJHc1Oc9IKW12I27AQtWsx5G0xO46IiPgRlYHfYrNDlytg8F/AFrhnVaqjk/nB3dlzZ8UH5oYRERG/ojIQQj6p6ee5sWIKGIa5YURExG+oDPyWZe/B5u+hqtzsJKfsK3cf3LZwyN0A2T+bHUdERPyEysCxVFfAjHth0u+geLfZaU5ZCU6ym2QAsOfH98nKLzM5kYiI+AOVgWPJWQvuKoiIg7gWZqc5JfFRDpx2G89s6QTA5sw5DBo3V4VAREQ0z8AxHTiUntw94CfuSY1zMntMBvkFPdmYm8FO2lH2wc/klVQGxqJLIiJSb1QGjuXQMhAEUuOcnh/8LZtQllVgdhwREfETOk1wLEFWBg4XRjW4a357QxERCWoqA0fjrobdqzy3k3uYGqU+NFnyN5aE30n0zh/MjiIiIiZTGTiK8PyNUF0OjmhIaGN2HJ+zVhQQbynGtfFTs6OIiIjJVAaOotLVGm75Dn4/EazBt5sKTrsUgNjNM4NiDgURETl5wfdTzkcMm8OzZHHHoWZHqRelTfuw00jAVlUEG2abHUdEREykMhCqLFZm1KR7bq/6yNwsIiJiKpWBOhk0/fFZWPIfqCwxO0y9+exAGVg3EyqKzQ0jIiKmURmoQyL5NF75Bnx+PxDYkw0dy0qjNRWxraC6DH6daXYcERExiSYdqkN76w7PjYQ24Ig0N0y9spDb5SZSrPmQ0tPsMCIiYhKVgTq0t2zz3GjSydwgDWBf5xtISXWZHUNEREyk0wR16GDZ7rmR1NncICIiIg1AZaAO7a37y0AIHBkAPEs1r/sSFk00O4mIiJhApwkO566hnWX/mIFQOTKwZx3871oIi4Ae10F4tNmJRESkAenIwGEcRduJsFThtkVAQmuz4zSMpl09gyWry2H9V2anERGRBqYycJhKVyt6lE9k0+8+BKvN7DgNw2KBTpd5bq+eZmYSERExgcpAHfKJoTwxOJctPqrOl3m+r58V1BMtiYjIkVQGxKNpN4hvvX8CIp0qEBEJJSoDh0mdez+Phf2XsNLdZkdpWBbLwaMDa6aZmURERBqYysChqsqIW/8Rt4R9QTBPQ3xUB8YN5G8Ht9vUKCIi0nB0aeGh9vyCxXCTa8RQ7Uw0O03DS+4OI5dAYjuzk4iISAPSkYFD5awF4Fd3c89h81BjsagIiIiEIJWBQ+39FYD1RqrJQfxAZSlUV5qdQkREGkDIl4Gs/DJWZRWwKquAwu1rANhopJicymRfPQYvpMG6L8xOIiIiDSCkxwxk5ZcxaNxcyqpqAJjtWEmsFXZYmxEf5TA5nYmsNqgq8VxVcOAKAxERCVohfWQgr6SSsqoaxl/Tgxkj02kVWQ7AX269nNQ4p8npTHTgqoJfv/KcLhARkaAW0kcGDkhLiqZLqgse2gTFOTSNTjI7UoPZkFNc6358lIPUlJ4Q1wLyt8GGWdDpUpPSiYhIQ1AZOJTFAjFNzE7RIOKjHDjtNkZPyaz1uNNuY/aYDFI7XQoLXvWsVaAyICIS1FQGQlRqnJPZYzLIKzl4xcCGnGJGT8kkr6SS1E6/95SB9V9DVRnYQ/i0iYhIkFMZOGD207DnFzjzdmiTYXaaBpEa5zz62IjU08HVHAq2w8ZvocPFDRtOREQajMrAAZvnQtZS6H6t2Un8g8UCfe+CqlLPzIQiIhK0VAYADAP2rvfcbqwZ+LzOvM3sBCIi0gBC+tLCA8LKcqCiECxWSGhjdhwREZEGpTIAhOdt8NyIbwVh4aZm8TsVRbDiA1j0b7OTiIhIPdFpAiC8YKPnRuP25gbxR7tWwse3QIQLet0AYSE8M6OISJDSkQEgPH//kYHGbc0N4o+anwnRTaC8wDPIUkREgo7KAIC7BuyRGjxYF6sNOv7Oc3vNNFOjiIhI/VAZALL7/QUeydJlhUdzYAbCXz6Hmipzs4iIiM+pDBxgtYLNbnYK/9SiL0Q2hrI82DLP7DQiIuJjKgNyhA05xazKKmBVVgFZ+WVgC4OOQz1PrvnU3HAiIuJzIX81wXnWpaR99DR0HgKDxpodx1R1LV5Ua+Gipe9AcY5p+UREpH6EfBloZ8kiIm8dFPYwO4rpDl+8qNbCRa3OgXtXg6uZySlFRMTXQr4MtLLs8tzQzINA3YsXbcgp3n8rBooLiI9yHH2BIxERCTgqA9YDZeA0c4P4obpOGwA0tZcx9d4LSU2INieYiIj4lMqAjgwc1eGnDQBcX9xB0x0z2b5pMiRcYGI6ERHxlZAuA5aqUppY8j13GqkM1OXw0wZ5UZHYLTXEbv4CeqsMiIgEg5C+tDC8cAsA1eHx4Iw3N0yAKGg9BADX5i/A7TY5jYiI+EJIlwFLdRm/uJtTntDR7CgBoyS1H4WGE3vpbtixxOw4IiLiAyFdBsqa9OLCyr+xZehks6MEDMMWzmx3L88dTUAkIhIUQroMyMn5suYMz401n4JhmBtGREROmcqAnLDv3d2osUdB4Q7IWmZ2HBEROUUhfTVB2w8G8IWjhrCC9yC1u9lxAkYFDvb0GEnTpCaQ0NrsOCIicopCtwxUlhBesIlOVlgbHmd2moCzt8comqa6zI4hIiI+ELqnCfZtBiDPiKYmIs7cLCIiIiYK3SMD+zYCsNVoEsI74RQV74G1n4ItHE4fbnYaERE5SSF8ZGATAJuNpiYHCWBbvofPx8D8F3VVgYhIAAvdMpB78MiAnKS2gyEswlOsdq8yO42IiJyk0C0D+8cMbHbryMBJC4+GtEGe26unmRpFREROXuiWgYTWlMe3Y7ORbHaSwNbpMs/3NdN0qkBEJECFbhm49J9suHI2K4zTzE4S2NoNBpsDcjdAzlqz04iIyEkI3TIgvhERC6ed57mttQpERAJSaJYBd40OafvQvlYXYVjCyN2zk1VZBazKKiArv8zsWCIicpxC8xL7pW/D7Kdp2vZKYJDZaQJaVn4ZQ7+Mw131GgXLomHZfACcdhuzx2SQGuc0OaGIiPyW0CwDeVugotDsFEEhr6SSvKowxl/Tj7SkaAA25BQzekomeSWVKgMiIgEgRMvAVgAqY1qYHCR4pCVF0yXVBcU5QLTZcURE5ASEaBnYAkCVyoDvuGvg7SGw9QccV88FPEcIDoiPcugogYiInwrRMnDgyEBzYI+5WYKF1QZh4QA0yfoap70bo6dkep/WGAIREf8VemWgLA8qCgCojG2ByoAPdboMNn6La9MMZo+5i7ySSkBjCERE/F3oXVq4/xQBUUkYYfrB5FMdhoLFBtk/k+reRZdUF11SXd6BhSIi4p9CrwxYbJ4FdtpkmJ0k+EQ1glb9PLfXTjc3i4iIHLfQKwPJ3eC6D+CK/5idJDh1utTzXQsXiYgEjNArA+ITG3KKWZVVUOuKAQA6/g6wwM5lkL/NlGwiInJiQm8AYWUJOKLMThGw4qMcOO22I64UiI9yeO5EJ0H/MZDYHiIbmRNSREROSOiVgdf7QUku/HEaoBULT1RqnJPZYzK8VwpAHXMInPeECclERORkhVYZcNdA/nZwV3l+gy3+7ZfIkVLjnLpEUEQkiIRWGSjc6SkCNgfEJEOx2kC9ydsKqz+G+FYQN9DsNCIicgyhNYDwwBwDruaeGfOk/vzyOcweC4v+bXYSERH5DaFZBuJbmZkiNHS6xPN920LCSnebm0VERI4ptMpAvmdNAuJbmpsjFLiaQbM+gEHslq/MTiMiIscQYmVgu+e7q7m5OULF/gmIYjd9YXIQERE5ltAqAyk9PFMRN+1qdpLQ0NFzqiBq1480osDkMCIicjShVQbOusMzFXHb881OEhriW0JKTyyGmwtsP5mdRkREjiK0yoA0vE6X4g5zEq9JHURE/FbolIHqSijXoeoG1/tm1l6/nNdqLjU7iYiIHEXoTDq0YzG8czGViV359bLPAY5cZEd8LyIWw26YnUJERI4hdMrA/isJluYYDHt1vvfhWovsSL2yF26F1G5mxxARkcOEThko8JSBbTWNGX9ND9KSooE6FtkRn7PUVPCF4xHaT9kK96zQPA8iIn4mdMYM7J9wKMtoTFpSNF1SXXRJdakINADDFk6+sX/Z6NUfmxtGRESOEEJlwHNkIMtobHKQ0DTd3ddzY9VUc4OIiMgRQqcM7D9NkIXKgBlm1vTBsITBrpWw51ez44iIyCFCowy43VCwA4AdRqLJYUJTPjEUNTvHc0dHB0RE/EpolIHqcug5nKLmA9llxJudJmQVnLZ/JcNVH4Ghyw1FRPxFaJQBRyQMfZGtF75DdQhdQOFvilpeAGERkLsBsn82O46IiOynn4zSYNyOaBj0NMS3gqROZscREZH9QqMMlOSCLTT+qH7vrNvNTiAiIocJjdME3/0Fnm9B4rLxZicRERHxO6Hx6/L+ywqrI5uYHEQAyNsCSyd5xnKc84DZaUREQl5oHBnI3wZAZXSqyUEEgL0bYP6LsGgi1FSbnUZEJOQFfxkwDO/sg1XRzUwOIwC0yYDIRlCyBzbPMTuNiEjIC/4yUJYHVSUAVEWnmBxGALDZofPlnts/TzE3i4iIhEAZ2H+KgOgmGGER5maRg7pf6/n+ywyoKDY3i4hIiAudMuBqbm4OqS21FyScBlWlnkIgIiKmCf4y4GoGvW+GDhebnUQOZbFAt2s8t1foVIGIiJmC/9LC1NM9XwBZBeZmkdq6XQ2LJniOEBiGpyCIiEiDC/4yIH5jQ07tsQHxUU1JvX+9Z0ChiIiYJvjLQO5GiGoMES6zk4Ss+CgHTruN0VMyaz3utNuYPSaD1DiVARERMwV/GfjPeZ7LC+/8EdClhWZIjXMye0wGeSWV3sc25BQzekomeSWVpLoiYPsiiE2BuBYmJhURCU3BXQYqij1FADwDCfe6zc0TwlLjnKTGOet+8rN7YNkkOHs0nP90g+YSEZFgv5qgYIfne4QLwmPMzSJHd9pAz/eVH4JbhU1EpKGFRhmI1TTE/mpDTjGro9OpccRCYRZsnW92JBGRkBPcZaBwfxlwqQz4m0MHFV484Sc+KO0FQMlP75ucTEQk9AT3mIGCLM93l1Yr9DeHDyrMW1MFP3xHxK8zoKoM7EcZXyAiIj4X5EcG9peBWJUBf5Qa56RLqosuqS7iO2aww2iMraoI1n1hdjQRkZAS3GXgtIHQ+yZofobZSeS3WKxMqznbc3v9bHOziIiEmOA+TdD1Ss+XBIT3q8/j4kuH0brXYLOjiIiElOA+MiABZSeNKUnpC1b9sxQRaUjB+3/dqnLYvRrK8s1OIiejutKzeJGIiNS74C0De9fBhL7wz95mJ5ETNftpGNcediwxO4mISEgI3jJQoCsJAlZRNpTtg+X/NTuJiEhICN4ycOCyQk04FFA25BSzudllANSsnMrOPbnmBhIRCQHBWwa8UxHryEAgOHRGwoFTq9jmTsRWVcz4V18kK7/M7HgiIkEteC8tLNTsg4Hk8BkJw5deD8te4lLjO/JKHjz6iociInLKgvjIgMYMBJpDZyRs0v9GAM62rcZetMPkZCIiwS14y4AWKQps8S0pTukLQNz6j0wOIyIS3IL3NEGfWyBvCyS0MTuJnKTczjfy/rZ4zm19MU3MDiMiEsSCtwycfbfZCeQUFbUazF+ro+gb39bsKCIiQS14TxOIiIjIcQnOMlC02zMVcXmh2UnklBlEZc2Hj26C4j1mhxERCUrBeZpg1Ufw1aOUtruUTRmveh/ekFNsYig5ORaaLPkb7PkZkrvD2feYHUhEJOgEZxnYf1nh/35x8+yK+bWectptxEc5zEglJymvwx+I3PMzLJ0Efe8Gi8XsSCIiQSVIy8B2ALbXxDP+mh6kJUV7n4qPcmgCmwBTcNolpC56FvZthC3zoXV/syOJiASV4BwzsH/2wWyjEWlJ0d6JbLqkulQEAtCveQb72lwCQOmPb5qcRkQk+ARnGdh/mmCn0cjkIHIqDl2v4I8/dwIg7JfPyM7OMjmZiEhwCb7TBNWVULwb8BwZkMBVe72CfuR/8D5xBWvg58mQPMbseCIiQSP4jgwUZQMGbquDXGLMTiOn6ND1Ckq6Xs8GdwrVTpU8ERFfCr4jA44oOO9J9u7Lx1gYfF0nlOW1v5ahs1syI60/zc0OIyISRIKvDEQ1hv5jyMkqgIXzf3t7CRzWMECXFYqI+Jp+dZaAY6kuh+X/heIcs6OIiASF4CsDOb/A7tVYqkrNTiL1pMWsW+DTkbBsktlRRESCQvCVgW+ehgl9iV8/1ewkUk8K0i7z3PjpbaipJiu/jFVZBd6vrPwyU/OJiASa4BszULADgMroFJODSH0paH0xzRb/GQqzyF0+jUGfRlNWVeN93mm3MXtMhiaYEhE5TsF3ZGD/7INVUSoDwcoIi4DTRwAQvuxNyqpqGH9ND2bc1Y/x1/SgrKpm/9wEIiJyPIKrDFSWQmkuAFXRySaHkXrV+yawWIneuYDTLFneaacPXYdCRESOT3CVgcKdnu/2KNwOl7lZpH7FNYd2FwEw3DbL5DAiIoEtyMqAZ7wArlQtcxsKzvgTAImWfHNziIgEuOAqA/sXKCI21dwc0jBaD+DXq79nZNVos5OIiAS04LqaIKUHnPeUykCosFqpdLUCdpidREQkoAVXGWjS2fMFkFVgbhZpUGHF2bA3B0gyO4qISMAJrtMEEpIut35P+8lnw1ePmh1FRCQgBVcZ2DIfdq2Cal1jHkqWGu3AqIH1XxOet97sOCIiASe4ysD718LrZ0PeFrOTSAPaajSlqOUFADRa9ZbJaUREAk/wlIHyAqgs8tx2aQBhqNnb1XOZYdz6j4in0OQ0IiKBJXgGEB64rNAZD44oQAMIg9WGnOIjbpc2PQOSe2DNzuQPtm+BISalExEJPMFTBgoPzDHQzNwcUm/ioxw47TZGT8ms9bjTbiM+OhzSR8LHtzAi7Gv21FSYE1JEJAAFTxkoOGT2QQlKqXFOZo/JOGIRovgoh2eFwujLqPrqCaKK8yjKXQstdJmhiMjxCL4yoAmHglpqnPPoSxOHOdg2aCK/n7Kb95N6NGguEZFAFjwDCA+cJtCRgZBWltSTQrRyoYjIiQieIwPdr4XG7aB1htlJxB8YhmfOiaZdzE4iIuL3gqcMtBlAVsKZnvPJWQW1RpxLaAmjmtYzroJdi+G2eZDc7YhtsvLLjj72QEQkxARNGcjKL2PQuLmUVdV4H3PabcRHOUxMJWaoJoyqqKaeO/NfgqvervXDP7ekktvfW1rr3wp4/r3MHpOhQiAiISc4ykBlCVVrv6JF9W7uuOYS0pI854z1m17o2tv9TuI2Toc109i15QEGvbntiKI46aYzaLS/LG7IKWb0lEzySir1b0ZEQk5wlIG962n11Y381+Fid9If6JLqMjuRmKy8USdoewGs/xrHj69SVjWU8df0UFEUEalDcFxNsP9KgiyjkclBxK/0uxeAuF8/Iok80pKi6ZLqokuqS0VAROQQwVEG9s8xkK0yIPttyClmVVhnSpr0xuqu5OawL8yOJCLit4LjNMEhZaC5yVHEXIdPWXyu9VzedvxEf9tqXJHB8c9dRMTXguP/jvtPE+zUkYGQd8SUxcbZbN3WAVeHC0mNjzI3nIiInwqOMrB/xUKdJhCoY8riZleaF0ZEJAAEx5iBwgNlIMHkIOLXqsoh+2ezU4iI+J3gODJw/tPs2rqOTfOSzU4i/mrPr/DuJVBTBaNXgEOnDEREDgjYMlBrOtn4QWyoOot8Mk3NJH4soQ2ERUBRNix+A/qNNjuRiIjfCMgyUNfUw6Dph+UYbGGQ8SBMuwMWvAJ9/gThWt1QRAQCtAzklVRSVlXD+Gt60CliL478jVS6TiMqpZ0mk5Gj63o1fP8C7NsES97wTkokIhLqAnoAYVpSNO3yvqfVVzfSbs3LKgJybLYwOOdBz+0fXoGKInPziIj4iYAuA4D3skJiU83NIYGh61WQcBqU7fOMHRARkSAoA4We2QdxNTM3hwQGWxhkPOS5nbvB3CwiIn4iIMcM1KIjA3Kiul4JSR0gubvZSURE/EIQHBnYXwZcKgNynKw2FQERkUMEdBmw1FRCcY7njktLFMlJKMiC1Z+YnUJExFQBfZogrGQXYHgmk4nUugRygnI3woS+YLixXzXH7DQiIqYJ6DJQExEHl78BFYVgsZgdRwJNQhto1ge2zCNp6YvA5WYnEhExRUCfJnA7YqHb1Z7Z5EROlMUC5z8NQNz6qbS3bDM5kIiIOQK6DIicstRe0OlSLBg8EDbF7DQiIqYI6DIQmb0Ifv0KinaZHUUC2cAnMSw2BtmWe/5NiYiEmIAuA41XvA7vXw3rvjQ7igSyxmns6zAMgLgf/syqHfmsyiogK7/M5GAiIg0joAcQ2ouzPTc0+6Ccosp+D5C/Zhrv72nF+H/OpZownHYbs8dkaM0LEQl6gV0GSnZ6bmj2QTlFyamt2DnqZwZU2hkAbMgpZvSUTPJKKlUGRCToBWwZcFJOWEW+545mHxQfSElsTIrZIURETBCwYwZSLLmeG44YiHCZG0aCy/YltJpxDcnkmp1ERKRBBOyRgWTLPs8NHRUQX5s9lujshTxstwCXmp1GRKTeBeyRgeQDRwY0eFB87cK/YmDhUtsCInctMTuNiEi9C9gysKCmM9vPfQXOvN3sKBJskruT1/4az82FY8HtNjePiEg9C9gykEUiBWmXQdvzzY4iQWh37wcoNJw4966EzP8zO46ISL0K2DIgUp9qIhN5pXr/wkWzn4LSfeYGEhGpRwFbBi6xLiB62zdQUWR2FAlS79QMpjy+HZTmwtJ3AMjKL2NVVoH3S7MUikgwCMyrCQyDv9r/Q/RX/4S2SyE8xuxEEoSqCWNnv+doQxb0HE5WfhmDxs2lrKrGu41mKRSRYBCQZcBaWUC0pdxzJ1bTxEj9KW3aB1IHAZBXUklZVQ3jr+lBWlK0ZikUkaARkGXgwJoE1eHxhDkiTU4jocJaVcKZlrWkJfWjS6omuhKR4BGYZWD/mgRV0SmB+QeQwJO/nbQPL+AtRy47ii4CVAZEJHgE5ABCe/H+MhCVbHISCRmxqVTFNCPKUkHK/EfAMMxOJCLiM4FZBko8pwmqojVeQBqI1UpW/79RYdiJ2TEXfv6f2YlERHwmMMuAjgyICSrjTuOl6is8d2Y+TFjpbnMDiYj4SECWgb3dbuPuypEUtRhkdhQJMW/UXExZ465QXkDK/McBgw05xZp7QEQCWkCOv6to1JHp7lxuTWhvdhQJMTXY2HHOP2g77WJit37F7x0dGT3FUmsbzT0gIoEmIMuAiJkqGnWE/mMgZy0P9ruJm4nzPqe5B0QkEAVeGSjLJ2HNe2RYi4B+ZqeRUJXxMFitJAMauSIigS7wysDeX0n54XH+Ym9MPiPNTiNBbkNOcZ23sR423GbfZkho3UCpRER8K/DKQP42ALKMxkSZHEWCV3yUA6fdxugpmbUed9ptxEc5Dj5QWQrTR8G6L+H2+UDjBs0pIuILgVcGCrYDnjLQzuQoErxS45zMHpNBXkllrcfjoxy1xwKERUBxDlSVwse3woUfNHBSEZFTF3hlIN9TBnaoDEg9S41z/vYgQKsVfv86vNYXsn4iafnLwJkNkk9ExFcCb54B72mCRJODiOznagZDXwQgcdkrpFtXmxxIROTEBF4ZOOQ0gYjf6Hol9ByOBYOX7f9i2/atmoRIRAJGYJ0mMAzvaQKVAfE7F/2dqq2LSNr3K87PRzG06kHAokmIRMTvBd6RgeEfs/3cl1UGxP84IrFf+y7Vrpa0+t3DzLirP+Ov6UFZVc0RAxFFRPxJYB0ZsFigxVkU2DpSyXyz04gcKakjYXcvo7Wt9n9ateYooI6rEkRETBRYZUAkEBxSBBIrttDanlfnfAU6dSAi/iKwysDWBZCzhghHR7OTiPy2Dd/Q5IM/8lVKGuuHfIARFuF5WOsXiIifCawysOZTWPQ6rm63ARlmpxE5tkangTUMx+5MOv/8Z7jk1VpPH3rqQKcNRMRMgVUG9l9JUBXdzOQgIschvhVc+Sb890pY9i6k9ITeN9U51bFOG4iImQKrDBR4JhyqjFEZkACRNgjOewK+eQa+eAASTiO1TUatqY512kBEzBYwlxZm5ZdRs28rABsrE0xOI3IC+t0HXa4EdzV8MBz2biA1zkmXVBddUl2kJUWbnVBEQlxAlIGs/DIuHfcltspCAO7+cu+Rq8eJ+CuLBS79FzQ7A8oLYOGrv/0aEZEGFBCnCfJKKmlUvRtsUB3uYsot52vAlQQWewRc+3+w+N+Q8ZDZaUREagmIMgCQatkLQFh8S7qkukxOI3ISopNg4OMH7xuG50tExGQBUwaWuDuw6Xcf0aaRjgZIEKiphs/vg/AY6PKg2WlEJMQFTBkoIpLSpmeAjgpIMNj6AyybBEAjtwvobG4eEQlpATGAUCTotMmA858FIHnRX/i9dZ7JgUQklAVMGbjR9iXxa96D4j1mRxHxjbPvhvRRALxgn0js5i9MDiQioSpgysA9YR+T+sNjUKIyIEHk/GfJa3slYRY3zb8ZBeu+NDuRiISggCgD1op84iwlnjvxLc0NI+JLVitZ57zAtJq+WIxqaj66mbUbN7Mqq4Cs/DKz04lIiAiIAYSOov1rEjgTsTuiTE4j4lvxMU4eZxTuGiszKs/i2zfWAFqvQEQaTmCUgULPmgRVMS2wm5xFxNdS45x8NWYgeSX9uA+4D896BQ9M+anWegVZ+WXe9QwO0ORbIuILgVEGivYvUBTbgkiTs4jUh9Q4Z60f6vbCbcx23A9b/wqpV5GVX8agcXMpq6qp9TodPRARXwiMMlB4sAyIhIJGq96ksTUHY9ZtEG2Q12gwZVU1jL+mh3dhI612KCK+EhADCL1HBmJUBiQ07DrrCabW9Mdi1MDHt5Kw5j0A0pKitdqhiPhcQJSBHQNe5KqKJylulmF2FJGGYQ3j/qrbyO10A2CQ8sNj3Gn7VGsZiEi9CIgyUB3ZhCVGB6ojk8yOItJgDKxk930aznkAgAftU0iZ/6hnXQMRER8KiDIgErIsFhj4ONnpT+E2LETsXQk1lb/9OhGRE+D/ZWD3aposfo6LrIvMTiJimtwuN3NT1f1sG/wWOHRNjYj4lv+XgR1LSPx5AlfZ5pqdRMRUc9w9a50qa7TyP3SzbDQxkYgEC/+/tDDX8z+7rUYTNGJAQs2GnOJa373WziD5x2f40BHG3l8ckHq7CelEJFgETBnYZCTTx+QoIg0lPsqB025j9JRM72NOu434KIfnTutzKGx5AbFbvyZ13kNQsgaGvABh4eYEFpGAFgBlYAMAm41kk4OINJzUOCezx2TUmn641tTDEbFsO//ffDHhQR6wf4hl2SRKt2dSeMlbNG2eZlJqEQlU/j1mwF0D+zYBsNnd1OQwIg0rNc7pnWCoS6rriFkG46MjeNt6BSMqHyTPiCZyz8+E/2cAe5dPNymxiAQq/z4ykL8N3FW4beHspJHZaUT8ysGjB+nkFF2C5ctbiC9Yw7bi4t9+sYjIIfz7yMD+8QKVsa0w/DyqiBkOHD1o36ELWVd8yp2Vd1PY5uKDG1SVmxdORAKGf/+ETTsP7lvL9oGvmp1ExO8ZtnC+cJ918IGiXfDq6fDDyyc1a2FWfhmrsgq8X1n5ZT5MKyL+xL9PE1gsEJtCRUIUMN/sNCKBZdm7UJgFs56E1dPg0n9Bk07H9dK6lkzWcskiwcu/y4CInLxzHoCYZNwzH8W6cxnuieewp+dd7O1+J4bNUWvTWlcqAHkllbWWTNZyySLBzb/LwGf3gDMBW6vhZicRCTwWC1ltrmRYmY0neIPzWUaTpS+St+RDnqy6gcVGR++mR/ut/8CSySIS3Py3DFSVwdJ3PLdVBkSO26GzFW7IKWZblYuSq99je9G3JC98ig7l23mtVza70m/xbjN6SiZLNu8jLyn6iPcQkeDnv2Vg//wCRLioiUgwN4tIAKhr1kLw/Nbfp00jUuP+CH2GwrxxNM54iMYRsQA0Ip9Yu1Hn67wzHopIUPPfMrDnF8/3Rm09AwlF5JjqmrUQDhsPEJkAg/9y8EnDIPmr21iWkM3OXg9Q2Gao97+3w8cRiEjw8t8ysHuN5/txjn4WEU8hOKEf4HlbIHcDYSV7aPHtSPjlTTj/GWjdv94yioj/8d95BnLWer4ndTY3h0gwS2gNd2fCgEfAHgU7l8GkofDfK2D7ErPTiUgD8eMysNrzXUcGROpXeDQMeBjuyYQ+t4A1DDbMhjcHwaY5ZqcTkQbgn6cJqsqhZK/ndlJnyDc1jUhoiE6Ci/8B6XfCvHGQtRxaHTxd0MyyBwyj1kuy8suOvrKiiAQM/ywD9gh4eDsUbIOoRpBfYHYikdCR0MYzW2F1JVhtAFiqy5nmeILoqa9B/1HQ9WqySgzNUigSJPyyDBz8bSMeSgt0zbOIGcIOXlYYsW8tEVQSkbcOpt8Fs5/G3uF6oqra89w1GZqlUCTA+V0ZqGtOdNA1zyJmKkvqSd+KV/kqYwvJv7wLBdtJWjaeheE2SldcgGvI05DUFDhywiKdOhDxf35XBvJKKnnSeJ3+p0VQduZoKhp5pkzV/1BEzFVIFLndbiP5gvtg7XRKv/8nkTlLcW3+EnjGO+nRvVOW1VpyXKcORPyf35UBgPNtS2mcVQiNHgTNiy7iX2xh0OVyNsWfx/3/fJ+3M0pJTmxHKjB7TAZRn91KWNleCk67lMzocxj5yWadOhDxc35XBsJKd9PYUoiBBUtie7PjiMgx/GK0ILdrP5L330+NqIQtM6GmkuidC0i22nnD3g3Xxn2QeDk4oup8H12VIGIuvysDzj0/A1AR35aIo/yPQ0T8VIQLRv0Eq6bCqqlYd6/ifNtS+HYpfH8/pI+E856s9ZK6xgnp1IJIw/LDMrACgLLEHkSYnEVEajt8RcQ6xbeE/vdB//tYv3IxM6f8i1sTlhNeuBWchyw6VpILyyZRFnsG5VVVjL/mdF2VIGISPywDniMDZYndiTc5i4h4HGtFxGNd5VOR0J5x1VfTfMBf6GzfSbWzETVZnnlD4tZ9TLPvnyYN+Ck8Btuqc4nrfAH2qN71+CcRkbr4Vxlwu71loDSxu8lhROSA41oRsQ7eEvHBz/sf2eN9LsO6h+G2npxlXUsjSxFsnA4bp9MemO1IYfv6V1lFn+P+LBE5ef5VBsr2URnTgrLyCioSOpidRkQOccIrInL0EuHRDxjJ1ppKkopWkbh7AWz6DiNrKWnWnVw9cw/7Zs4H4AbbTM6wrae0z/lYmvehIqEDcbExKgciPmIxjMMmG69DYWEhLpeLgoICYmNj6zXQqqwCrnj1W6beNZAuuqxQJPSU5bF33UJ2JZ7tfSh1+rXE717gvV9p2FhPC1p1PZuoVr2gx/W1Zkw84PCrFEBHGCS0HO/Pb/86MrBfBZppUCRkOeNp3GMIjQ99bMiTFP7yHZbtP+Lc8zOOinw6sxlWbYb1n0GvGw9uu/A1qC4nN+o0RnxSwMaq+GNOgqTCIOJPZcDthooC/HlVZRExSct0Ylume24bBuvWrealdz/k2T6VJEaFgcVycNvF/4a8zTQCZtug2uGkMr4tFfHt2B7elkt+6uq9UuFY05/r0kYJJf5TBnYuhzfPp0Xzc4GbzE4jIv7KYqEqpjkz3WdwYasepCVFw/4rFOIj7aSe/kfYvZqynaux5q4nvKaMsL0riNy7gvDEHkBX71vF/e9i/mspJDGtI+FN0qiKTmVLVTyPfZdPfkHhMcuAJkqSYOIXZSArvwz70k9JMmooqtaRARE5tmNd6vj68OE0auNgQ04xY6Ys5cvhqbSz7IA9v5JX6YTt++dIcFfTKednelmrYcd62OF5j2bA3HDYN+0dVl05w/t5qZkvgz0SYpqylzju+HALO6piyCMaA6uOJkhAM70MeA7TzWG65SOSrDBuSxutUCgix1TXVQq5JZXc/t5SRry12PuY0+4gKrUTxPXyPJBfhvP7uYyekokFN50sz9A2LIen+0fiKtsOBTuoyttO1b7tLNwbwchXPVczRNotrLb/A4u7CoDGwHQbYAPDYmNXkwzSt/zp4ERJc18Amx2c8RCZ4PnujCe7ysm+miiMsINTqumIgvgD08tAXkklXarX0DY8C3eYkz+NuIsx8Y30H4eIHFNdlzoeXhAO/0FbV4mIj3LgOmQbO5CTV0qrwiJmhEWwIaeYh6YsZu/pfyLRvReKd1Oev4vSfTtJsBRjMWqIdIYD+484GG46z3kei1F9ROZkYEtNJ4ZVPe597M3wF4lIjcHmdFHjiMYRGUtMbAKEx0B8K2h/4cE3yN0IYeGeNR7skWBz1B4vIXKSTC8DALeGfQ6AteuVdGrdzOQ0IhKojmcuhOPaJj6S1PhI7/0KHPzQ6i7P+ATwTpk8Y+SZdHFVUlZQinPDBkZPycRBFQ+FnU+cpZhG1hJ6JhpEVBVCWR62inxaNktlxtB+AOQWV3D2+8sI2+muO0ir/tD+Qu/4hA7vnkdYRd4hG1g8pcDuhOZnwLD/HXxq6i1QWex5zu6EMCdFbjtlhp2qqGTyOvzhYFla8ylUV4DNTm65haIqC4bVjmFzEBUbT5O2vQ6+b/EeTwGxhh32ZVMxCWCml4HE5a/SxbYUwxKGJX2k2XFERGo55lTMMVEQ25imsTB7TOohRxzO9Z62KNtx6AJMVmZfcRZdGu+fQ8Vdw76LJ1BWVIC1qpj8vFzmrd7ClV1iSbBVQFLHWlc8LA43iMOGw3LgPQ2oKoGqEiqK81i/fyAlQIf1swkr31crc8z+rxXu1lwyq8X+MRa9SP/yMRxF2wFotP/rgI1GCtX3LjtYoN69BHLW1L2zXC3g3pWA5xSw68Mrichdi2G1YbGGERYWBhabpzxENoKbvzr42i8ehN2rwGI9pFxYPV9h4XD1uwe3nfci7FrpKR8HtjnwhYWsjBfIK/Wc0on/5X9E5K4h3G4jOsJxyLYWwAIDn/DOUZH701Rqdq7A2P8+YDmk4FjY2/Vm4lwuz77Y+C1krzj4PnDwtsUCPYdDxP7r+rcuhF0rDtvukO07/95zOslEx1UGDsxLVFhY6PMAZXt3UFhhsKfbn0iMSIV6+AwRkZMVY4VPbulJfmntuQjiIh3EWKsoLKzybhcTc/A34xYx4Ue8Li7SQYzDVuv/pWEdhhCz//bWnQX8efGPRKd2pU2iZ9XWTSu3UlJcxPOXd2VT4nw27Snh8Y+X8/zv2tIm3oaluozComL+OnM96/7xtfd9L7ReSbSllHCqcFJJuKWSaGs156XF4oxL5rXTOjJ68nKGT5jDX+ypJBKFw1KDw1JD6/gw7NRQXVnBuqJY8ldu9eZpWVBGVEXdc9VVllaz4Zft7CutYvTk5UyybKWzdW+d21ZHNOLXX7Z777dct4SonKV1buu2RfBLt4PbNs+cTczO+XVuC3DugoGUV3mOtrxon8IFtqW4gbp+uqxN+SNGWAT7Sqso+PDfXGxdeNT3HfZNU8rtcYy/tiedfp5Mwq+Tj7rtentvqqJTAGiy5H80WvPOUbfdWNOG2GadSYz1/fJ8B/6t/db8gsc1A+GOHTto3ry5b5KJiIhIg9q+fTvNmh39NPxxlQG3283OnTuJiYnB4uNzQoWFhTRv3pzt27fX+1THoUz7uWFoPzcM7eeGof3cMOpzPxuGQVFRESkpKVitR790/7hOE1it1mM2Cl+IjY3VP7YGoP3cMLSfG4b2c8PQfm4Y9bWfXa7fXudHM/yIiIiEOJUBERGREGd6GQgPD+epp54iPDzc7ChBTfu5YWg/Nwzt54ah/dww/GE/H9cAQhEREQleph8ZEBEREXOpDIiIiIQ4lQEREZEQpzIgIiIS4kwtA6+99hqtW7cmIiKCXr16MW/ePDPj+L3vv/+e3/3ud6SkpGCxWJg2bVqt5w3DYOzYsaSkpOB0OhkwYACrV6+utU1FRQV33XUXjRs3JioqiksuuYQdO3bU2iYvL4/hw4fjcrlwuVwMHz6c/Pz8ev7T+YfnnnuOPn36EBMTQ1JSEpdddhnr1q2rtY3286mbMGEC3bp1806ykp6ezpdfful9Xvu4fjz33HNYLBZGjx7tfUz72jfGjh2LxWKp9dW0aVPv836/nw2TTJ482bDb7cYbb7xhrFmzxrjnnnuMqKgoY+vWrWZF8ntffPGF8dhjjxlTp041AOOTTz6p9fzzzz9vxMTEGFOnTjVWrlxpXHPNNUZycrJRWFjo3eb22283UlNTjVmzZhnLli0zzj33XKN79+5GdXW1d5sLL7zQ6NKli7FgwQJjwYIFRpcuXYyhQ4c21B/TVIMHDzbefvttY9WqVUZmZqZx8cUXGy1atDCKi4u922g/n7rp06cbn3/+ubFu3Tpj3bp1xqOPPmrY7XZj1apVhmFoH9eHxYsXG61atTK6detm3HPPPd7Hta9946mnnjI6d+5sZGdne79ycnK8z/v7fjatDJxxxhnG7bffXuuxDh06GA8//LBJiQLL4WXA7XYbTZs2NZ5//nnvY+Xl5YbL5TJef/11wzAMIz8/37Db7cbkyZO922RlZRlWq9WYOXOmYRiGsWbNGgMwfvzxR+82CxcuNADjl19+qec/lf/JyckxAGPu3LmGYWg/16f4+HjjP//5j/ZxPSgqKjLatm1rzJo1y8jIyPCWAe1r33nqqaeM7t271/lcIOxnU04TVFZWsnTpUi644IJaj19wwQUsWLDAjEgBb/PmzezatavWPg0PDycjI8O7T5cuXUpVVVWtbVJSUujSpYt3m4ULF+JyuTjzzDO925x11lm4XK6Q/LspKPCsD5+Q4FlrXPvZ92pqapg8eTIlJSWkp6drH9eDkSNHcvHFFzNo0KBaj2tf+9b69etJSUmhdevWXHvttWzatAkIjP18XAsV+drevXupqamhSZMmtR5v0qQJu3btMiNSwDuw3+rap1u3bvVu43A4iI+PP2KbA6/ftWsXSUlJR7x/UlJSyP3dGIbBfffdR79+/ejSpQug/exLK1euJD09nfLycqKjo/nkk0/o1KmT939q2se+MXnyZJYtW8aSJUuOeE7/nn3nzDPP5N1336Vdu3bs3r2bP//5z/Tt25fVq1cHxH42pQwccPhyyIZh+HyJ5FBzMvv08G3q2j4U/25GjRrFihUrmD9//hHPaT+fuvbt25OZmUl+fj5Tp05lxIgRzJ071/u89vGp2759O/fccw9ff/01ERERR91O+/rUXXTRRd7bXbt2JT09ndNOO41JkyZx1llnAf69n005TdC4cWNsNtsRTSYnJ+eI5iTH58Co1WPt06ZNm1JZWUleXt4xt9m9e/cR779nz56Q+ru56667mD59Ot99912t5bu1n33H4XCQlpZG7969ee655+jevTsvv/yy9rEPLV26lJycHHr16kVYWBhhYWHMnTuXV155hbCwMO9+0L72vaioKLp27cr69esD4t+0KWXA4XDQq1cvZs2aVevxWbNm0bdvXzMiBbzWrVvTtGnTWvu0srKSuXPnevdpr169sNvttbbJzs5m1apV3m3S09MpKChg8eLF3m0WLVpEQUFBSPzdGIbBqFGj+Pjjj/n2229p3bp1ree1n+uPYRhUVFRoH/vQeeedx8qVK8nMzPR+9e7dm+uuu47MzEzatGmjfV1PKioqWLt2LcnJyYHxb/qUhh+eggOXFr755pvGmjVrjNGjRxtRUVHGli1bzIrk94qKiozly5cby5cvNwDjxRdfNJYvX+69HPP55583XC6X8fHHHxsrV640hg0bVuelK82aNTNmz55tLFu2zBg4cGCdl65069bNWLhwobFw4UKja9euIXOJ0B133GG4XC5jzpw5tS4RKi0t9W6j/XzqHnnkEeP77783Nm/ebKxYscJ49NFHDavVanz99deGYWgf16dDryYwDO1rXxkzZowxZ84cY9OmTcaPP/5oDB061IiJifH+TPP3/WxaGTAMw/jXv/5ltGzZ0nA4HMbpp5/uvXxL6vbdd98ZwBFfI0aMMAzDc/nKU089ZTRt2tQIDw83zjnnHGPlypW13qOsrMwYNWqUkZCQYDidTmPo0KHGtm3bam2Tm5trXHfddUZMTIwRExNjXHfddUZeXl4D/SnNVdf+BYy3337bu43286m76aabvP/tJyYmGuedd563CBiG9nF9OrwMaF/7xoF5A+x2u5GSkmJcfvnlxurVq73P+/t+1hLGIiIiIU5rE4iIiIQ4lQEREZEQpzIgIiIS4lQGREREQpzKgIiISIhTGRAREQlxKgMiIiIhTmVAREQkxKkMiDSQAQMGMHr0aO/9Vq1aMX78eNPy1JexY8disViwWCw+/fO988473vc9dD+KyKlTGRAxyZIlS7j11luPa9tAKw6dO3cmOzv7uP98x+Oaa64hOzub9PR0n72niHiEmR1AJFQlJiaaHaHehIWFeZdt9RWn04nT6cThcPj0fUVERwZE6kVJSQl//OMfiY6OJjk5mXHjxh2xzeG/7Y8dO5YWLVoQHh5OSkoKd999N+A5vbB161buvfde72FygNzcXIYNG0azZs2IjIyka9eu/O9//6v1GQMGDODuu+/mwQcfJCEhgaZNmzJ27Nha2+Tn53PrrbfSpEkTIiIi6NKlCzNmzPA+v2DBAs455xycTifNmzfn7rvvpqSk5IT3icViYcKECVx00UU4nU5at27Nhx9+WGubHTt2cO2115KQkEBUVBS9e/dm0aJFJ/xZInJiVAZE6sEDDzzAd999xyeffMLXX3/NnDlzWLp06VG3/+ijj3jppZeYOHEi69evZ9q0aXTt2hWAjz/+mGbNmvHMM8+QnZ1NdnY2AOXl5fTq1YsZM2awatUqbr31VoYPH37ED89JkyYRFRXFokWL+Pvf/84zzzzjXTPd7XZz0UUXsWDBAv773/+yZs0ann/+eWw2GwArV65k8ODBXH755axYsYIpU6Ywf/58Ro0adVL75YknnuCKK67g559/5vrrr2fYsGGsXbsWgOLiYjIyMti5cyfTp0/n559/5sEHH8Ttdp/UZ4nICTjldQ9FpJaioiLD4XAYkydP9j6Wm5trOJ3OWkvHtmzZ0njppZcMwzCMcePGGe3atTMqKyvrfM9Dtz2WIUOGGGPGjPHez8jIMPr161drmz59+hgPPfSQYRiG8dVXXxlWq9VYt25dne83fPhw49Zbb6312Lx58wyr1WqUlZXV+ZqnnnrK6N69+xGPA8btt99e67EzzzzTuOOOOwzDMIyJEycaMTExRm5u7jH/jIcvwSsip05HBkR8bOPGjVRWVtYa6JaQkED79u2P+pqrrrqKsrIy2rRpwy233MInn3xCdXX1MT+npqaGv/zlL3Tr1o1GjRoRHR3N119/zbZt22pt161bt1r3k5OTycnJASAzM5NmzZrRrl27Oj9j6dKlvPPOO0RHR3u/Bg8ejNvtZvPmzcfMV5fDB/+lp6d7jwxkZmbSs2dPEhISTvh9ReTUaAChiI8ZhnHCr2nevDnr1q1j1qxZzJ49mzvvvJMXXniBuXPnYrfb63zNuHHjeOmllxg/fjxdu3YlKiqK0aNHU1lZWWu7w19vsVi8h96dTucxc7ndbm677Tbv+IVDtWjR4kT+iEd1YAzEb2URkfqjIwMiPpaWlobdbufHH3/0PpaXl8evv/56zNc5nU4uueQSXnnlFebMmcPChQtZuXIlAA6Hg5qamlrbz5s3j0svvZTrr7+e7t2706ZNG9avX39CWbt168aOHTuOmu30009n9erVpKWlHfF1MqP6D90nB+536NDBmyUzM5N9+/ad8PuKyKlRGRDxsejoaG6++WYeeOABvvnmG1atWsUNN9yA1Xr0/9zeeecd3nzzTVatWsWmTZt47733cDqdtGzZEvBcefD999+TlZXF3r17AU/pmDVrFgsWLGDt2rXcdttt7Nq164SyZmRkcM4553DFFVcwa9YsNm/ezJdffsnMmTMBeOihh1i4cCEjR44kMzOT9evXM336dO66666T2jcffvghb731Fr/++itPPfUUixcv9g5GHDZsGE2bNuWyyy7jhx9+YNOmTUydOpWFCxee1GeJyPFTGRCpBy+88ALnnHMOl1xyCYMGDaJfv3706tXrqNvHxcXxxhtvcPbZZ9OtWze++eYbPvvsMxo1agTAM888w5YtWzjttNO88xM88cQTnH766QwePJgBAwZ4f5CeqKlTp9KnTx+GDRtGp06dePDBB71HIbp168bcuXNZv349/fv3p2fPnjzxxBMkJyef+E4Bnn76aSZPnky3bt2YNGkS//d//0enTp0Az9GPr7/+mqSkJIYMGULXrl1rXdkgIvXHYpzMCU4RkaMYO3Ys06ZNIzMzs9bjFouFTz755KQKy6EGDBhAjx49AmpGRhF/pyMDIuJzK1euJDo6mtdee81n7/l///d/REdHM2/ePJ+9p4h46MiAiPjUvn37vIMAExMTcblcwKkfGSgqKmL37t2A57RK48aNfZJXRFQGREREQp5OE4iIiIQ4lQEREZEQpzIgIiIS4lQGREREQpzKgIiISIhTGRAREQlxKgMiIiIhTmVAREQkxP0/0aZvWYYjsOkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.distributions import Chi2, transforms, transformed_distribution\n",
    "\n",
    "L = np.array([350])\n",
    "prior = transformed_distribution.TransformedDistribution(\n",
    "        Chi2(6), transforms.AffineTransform(loc=0, scale=0.5 * L[0])\n",
    "    )\n",
    "r = prior.sample((10_000,))\n",
    "\n",
    "\n",
    "x = np.linspace(0, 5000, 500)\n",
    "plt.hist(r, 100, range=(0, 5000), density=True, histtype=\"step\", label=\"samples\")\n",
    "plt.plot(x, 0.5 * x**2 * np.exp(-x / L[0]) / L[0]**3, \"--\", label=\"exact pdf\")\n",
    "plt.xlabel(\"distance [pc]\")\n",
    "plt.yticks([])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_mean, theta_std = theta_mean.clone().detach().numpy(), theta_std.clone().detach().numpy()\n",
    "x_mean, x_std = x_mean.clone().detach().numpy(), x_std.clone().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Chi2, transformed_distribution\n",
    "\n",
    "class NeuralPosteriorEstimator(pl.LightningModule):\n",
    "    \"\"\" Simple neural posterior estimator class using a normalizing flow as the posterior density estimator.\n",
    "    \"\"\"\n",
    "    def __init__(self, featurizer, data, d_context=8):\n",
    "        super().__init__()\n",
    "        self.d_in = 3\n",
    "        self.featurizer = featurizer\n",
    "        self.flow = get_flow(d_in=self.d_in, d_hidden=32, d_context=d_context, n_layers=4)\n",
    "\n",
    "        self.data = {name: nn.Parameter(torch.tensor(data[name], requires_grad=False, dtype=torch.float32, device=self.device)) for name in data}\n",
    "        for name in self.data:\n",
    "            self.register_parameter('data_' + name, self.data[name])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.featurizer(x)\n",
    "    \n",
    "    def loss(self, x, theta):\n",
    "        def log_distance(distance, plx):\n",
    "            plx, e_plx = plx[:,0], plx[:,1]\n",
    "            likelihood = torch.distributions.Normal(1/distance, e_plx).log_prob(plx)\n",
    "            prior_prob = transformed_distribution.TransformedDistribution(\n",
    "                Chi2(6), transforms.AffineTransform(loc=0, scale=0.5 * float(self.data_L.data))\n",
    "            ).log_prob(distance)\n",
    "            return prior_prob + likelihood\n",
    "\n",
    "        actual_theta = theta * self.data_theta_std.data + self.data_theta_mean.data\n",
    "        actual_x = x * self.data_x_std.data + self.data_x_mean.data\n",
    "        plx, distance = actual_x[:,:2],  actual_theta[:,1]\n",
    "    \n",
    "        context = self(x[:,2:])\n",
    "        return -(self.flow.log_prob(inputs=theta, context=context) + log_distance(distance, plx))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, theta = batch\n",
    "        loss = self.loss(x, theta).mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, theta = batch\n",
    "        loss = self.loss(x, theta).mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37.0843, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'x_mean': x_mean, 'x_std': x_std, 'theta_mean': theta_mean, 'theta_std': theta_std, 'L': L} \n",
    "d_context=8\n",
    "\n",
    "npe = NeuralPosteriorEstimator(build_mlp(input_dim=x_samples.shape[1]-2, hidden_dim=16, output_dim=d_context, layers=2), data, d_context=d_context)\n",
    "(npe.loss(x_samples[:64], theta_samples[:64]) / x_samples.shape[1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npe.device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type       | Params | Mode\n",
      "---------------------------------------------------\n",
      "0 | featurizer   | Sequential | 952    | eval\n",
      "1 | flow         | Flow       | 21.7 K | eval\n",
      "  | other params | n/a        | 43     | n/a \n",
      "---------------------------------------------------\n",
      "22.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.7 K    Total params\n",
      "0.091     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "87        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[545], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpe.device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnpe\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, enable_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    322\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[542], line 43\u001b[0m, in \u001b[0;36mNeuralPosteriorEstimator.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     42\u001b[0m     x, theta \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[0;32mIn[542], line 33\u001b[0m, in \u001b[0;36mNeuralPosteriorEstimator.loss\u001b[0;34m(self, x, theta)\u001b[0m\n\u001b[1;32m     30\u001b[0m plx, distance \u001b[38;5;241m=\u001b[39m actual_x[:,:\u001b[38;5;241m2\u001b[39m],  actual_theta[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     32\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x[:,\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mlog_prob(inputs\u001b[38;5;241m=\u001b[39mtheta, context\u001b[38;5;241m=\u001b[39mcontext) \u001b[38;5;241m+\u001b[39m \u001b[43mlog_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[542], line 25\u001b[0m, in \u001b[0;36mNeuralPosteriorEstimator.loss.<locals>.log_distance\u001b[0;34m(distance, plx)\u001b[0m\n\u001b[1;32m     21\u001b[0m plx, e_plx \u001b[38;5;241m=\u001b[39m plx[:,\u001b[38;5;241m0\u001b[39m], plx[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     22\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mdistance, e_plx)\u001b[38;5;241m.\u001b[39mlog_prob(plx)\n\u001b[1;32m     23\u001b[0m prior_prob \u001b[38;5;241m=\u001b[39m \u001b[43mtransformed_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformedDistribution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChi2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAffineTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_L\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prior_prob \u001b[38;5;241m+\u001b[39m likelihood\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/torch/distributions/transformed_distribution.py:177\u001b[0m, in \u001b[0;36mTransformedDistribution.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    171\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m log_prob \u001b[38;5;241m-\u001b[39m _sum_rightmost(\n\u001b[1;32m    172\u001b[0m         transform\u001b[38;5;241m.\u001b[39mlog_abs_det_jacobian(x, y),\n\u001b[1;32m    173\u001b[0m         event_dim \u001b[38;5;241m-\u001b[39m transform\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mevent_dim,\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m     y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 177\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m \u001b[43mlog_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_sum_rightmost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "print(f\"npe.device: {npe.device}\")\n",
    "trainer = pl.Trainer(max_epochs=20, enable_checkpointing=False)\n",
    "trainer.fit(model=npe, train_dataloaders=train_loader, val_dataloaders=val_loader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[519], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m x_test \u001b[38;5;241m=\u001b[39m sim_forward(\u001b[38;5;241m*\u001b[39mtheta_test, bands)\n\u001b[1;32m      5\u001b[0m x_test_norm \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor(x_test) \u001b[38;5;241m-\u001b[39m x_mean) \u001b[38;5;241m/\u001b[39m x_std\n\u001b[0;32m----> 7\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mnpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_norm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m samples_test \u001b[38;5;241m=\u001b[39m (npe\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39msample(num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, context\u001b[38;5;241m=\u001b[39mcontext) \u001b[38;5;241m*\u001b[39m theta_std \u001b[38;5;241m+\u001b[39m theta_mean)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      9\u001b[0m corner\u001b[38;5;241m.\u001b[39mcorner(samples_test[\u001b[38;5;241m0\u001b[39m], labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mradius\u001b[39m\u001b[38;5;124m\"\u001b[39m], truths\u001b[38;5;241m=\u001b[39mtheta_test, discard \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m);\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/stark/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "import corner\n",
    "\n",
    "theta_test = np.array([7000, 200, 0.01])\n",
    "x_test = sim_forward(*theta_test, bands)\n",
    "x_test_norm = (torch.Tensor(x_test) - x_mean) / x_std\n",
    "\n",
    "context = npe.featurizer(x_test_norm[2:]).unsqueeze(0)\n",
    "samples_test = (npe.flow.sample(num_samples=10000, context=context) * theta_std + theta_mean).detach().numpy()\n",
    "corner.corner(samples_test[0], labels=[\"teff\", \"distance\", \"radius\"], truths=theta_test, discard = 5000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test With Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 0/352 [135:54:51<?, ?it/s, v_num=63, train_loss=9.670, val_loss=9.200]\n",
      "Epoch 6:   9%|         | 31/352 [135:35:37<1404:03:04,  0.00it/s, v_num=65, train_loss=inf.0, val_loss=inf.0]\n"
     ]
    }
   ],
   "source": [
    "def get_ngf21():\n",
    "    tap_service = pyvo.dal.TAPService(\"http://TAPVizieR.u-strasbg.fr/TAPVizieR/tap/\")\n",
    "    QUERY = f\"\"\"select top 1000 *\n",
    "            from \\\"J/MNRAS/508/3877/maincat\\\" as ngf\n",
    "            join \\\"J/A+A/674/A33/gspc-wd\\\" as gspc \n",
    "            on ngf.GaiaEDR3 = gspc.GaiaDR3\n",
    "            where ngf.e_TeffH is not NULL and ngf.e_loggH is not NULL and ngf.e_TeffHe is not NULL and ngf.e_loggHe is not NULL\n",
    "            and RAND() < 0.01\"\"\"\n",
    "    return tap_service.search(QUERY).to_table().to_pandas()\n",
    "\n",
    "ngf21 = get_ngf21()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
